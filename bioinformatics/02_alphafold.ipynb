{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习AlphaFold,UniFold的策略结合ESM-IF来实现Uni_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数1: 学习torch.split,在指定维度将tensor分成许多chunk tensor组成的tuple\n",
    "# 参数二可以写为一个single chunk的大小，要么是许多chunk size的大小加起来等于10\n",
    "x = torch.arange(10)\n",
    "x_chunk = torch.split(x,5,dim=0)\n",
    "# E.g.\n",
    "    #    # [*, N_res, H * P_q * 3]\n",
    "    #     q_pts = self.linear_q_points(s)\n",
    "\n",
    "    #     # This is kind of clunky, but it's how the original does it\n",
    "    #     # [*, N_res, H * P_q, 3]\n",
    "    #     q_pts = torch.split(q_pts, q_pts.shape[-1] // 3, dim=-1)\n",
    "    #     q_pts = torch.stack(q_pts, dim=-1)\n",
    "N_res = 100\n",
    "H = 10\n",
    "P_q = 4\n",
    "P_v = 8\n",
    "q_pts = torch.randn(5,N_res,H*P_q*3)\n",
    "q_pts = torch.split(q_pts, q_pts.shape[-1] // 3, dim=-1)\n",
    "# q_pts = torch.stack(q_pts, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数 1.5 : torch.chunk(input,chunk_size)\n",
    "# chunk_size指的是将tensor变成几个chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1089,  0.1828, -1.1277,  ...,  0.0441,  0.1841, -0.1688],\n",
      "        [-1.0839, -1.7649,  0.9898,  ...,  0.5986, -0.8992, -0.4005],\n",
      "        [-0.4315,  0.1409,  0.5621,  ...,  1.9601, -0.0056, -1.6909],\n",
      "        ...,\n",
      "        [ 0.2440, -0.4118,  0.0060,  ..., -1.3390, -0.4782,  0.8730],\n",
      "        [-0.7326,  0.6082, -0.5335,  ..., -0.1101,  0.5573,  0.8758],\n",
      "        [ 1.5065,  1.4604,  0.7707,  ..., -2.6308, -0.7498, -0.5366]]) tensor([[-1.3005, -0.1431, -1.2304,  ...,  0.6920,  0.0064,  0.0126],\n",
      "        [-1.4925,  0.1571,  2.0259,  ...,  0.6518,  2.2871,  0.0633],\n",
      "        [ 0.0748,  1.0305,  0.3305,  ...,  0.4663, -0.2982, -1.2689],\n",
      "        ...,\n",
      "        [ 0.6041,  0.5428, -0.5820,  ...,  0.5456, -0.5846,  0.5794],\n",
      "        [ 0.1015, -2.0565,  0.2441,  ...,  0.8954, -1.0636,  0.9557],\n",
      "        [ 1.5222,  0.5061,  1.4869,  ...,  1.4584, -0.2904, -0.7817]]) tensor([[ 0.5649, -0.2386,  0.0038,  ...,  1.2166,  0.2035, -0.0906],\n",
      "        [-0.1684,  2.3154, -1.6595,  ...,  0.1254, -0.4387, -0.0158],\n",
      "        [-0.0068, -0.5798,  0.8392,  ...,  0.6119,  2.4130,  1.5516],\n",
      "        ...,\n",
      "        [ 0.3751,  0.5770, -0.5759,  ...,  1.7951,  2.0098,  1.2675],\n",
      "        [ 0.9103,  0.6223,  1.0325,  ..., -0.5746,  2.0485, -0.4877],\n",
      "        [ 0.0203,  0.0680,  0.2390,  ...,  1.2833, -1.0149,  1.0174]])\n"
     ]
    }
   ],
   "source": [
    "# 函数2 : torch.unbind(input, dim=0)\n",
    "# Removes a tensor dimension.\n",
    "# Returns a tuple of all slices along a given dimension, already without it.\n",
    "# torch.unbind : 把某一个维度按1进行切割\n",
    "# torch.split  : 把某一个维度按照指定的chunk size进行切割\n",
    "torch.unbind(torch.arange(10),dim=0) == torch.split(torch.arange(10),1,dim=0)\n",
    "# E.g. *torch.unbind(o_pt, dim=-1) 其中*表示解压unbind产生的tuple 当作实参数\n",
    "o_pt = torch.randn((N_res,H*P_v,3))\n",
    "print(*torch.unbind(o_pt,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数3 : torch.nn.Softplut(beta=1,threshold=20)\n",
    "# SoftPlus is a smooth approximation to the ReLU function and can be used to constrain the output of a machine to always be positive.\n",
    "a = np.linspace(-10.0,10.0,num=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=16\n",
    "head_weights = torch.randn((H,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6482, -0.9007, -0.7718, -0.1868, -0.4537,  0.7549, -0.1214, -0.6609,\n",
       "         2.3571, -0.3103, -2.0868,  0.8933, -1.5520, -0.1901,  0.5534, -1.4012])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_weights.view(*())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dog is a class method,given <class '__main__.MyDog'>\n"
     ]
    }
   ],
   "source": [
    "# class 内部的装饰器 1.\n",
    "# 一共有三种class method的类型: instance method; statistic method; class method\n",
    "# instance method绑定的对象是instance，必须先创建一个对象之后才能调用该方法(函数定义时形参是self)\n",
    "# static method创建的时候不需要添加self 形参,可以在不创建对象的时候就调用该函数，避免了创建对象所带来的内存消耗;另一个角度理解是static method本身就是一个普通的函数，只是挂靠在class的这个命名空间底下而言，不需要实例化对象\n",
    "# classmethod  类方法主要是为了优雅的创建多个对象\n",
    "class MyDog:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def instance_method(self): # self 形参接受的是实例化后对象的IP地址\n",
    "        print(\"My dog is an instance method\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_method():\n",
    "        print(\"My dog is a static method\")\n",
    "    \n",
    "    @classmethod\n",
    "    def class_method(cls): # cls参数表示这个类本身\n",
    "        print(f\"My dog is a class method,given {cls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 内部的装饰器 2.\n",
    "# @property 将一个method的调用方法变成属性的调用方法\n",
    "# @property 将某个方法变成只读属性\n",
    "# @xxx.setter 把该属性进行赋值\n",
    "# 注意属性的方法名不要和属性名重名,否则self.birth调用时会递归的找self.birth这个函数造成栈溢出\n",
    "class Student:\n",
    "    def __init__(self) -> None:\n",
    "        self._birth = 10\n",
    "    @property\n",
    "    def birth(self):\n",
    "        return self._birth\n",
    "\n",
    "    @birth.setter\n",
    "    def birth(self,value):\n",
    "        self._birth = value\n",
    "a = Student()\n",
    "a.birth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 0. Rigid Transformation\n",
    "\n",
    "如果对坐标做变换，如何存储transformation\n",
    "\n",
    "1. Rotation 是一个类似张量的 Rotation 对象，每一个point代表一个Rotation\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional,Tuple\n",
    "# Q1 : 3*3 旋转矩阵到旋转四元数的变换？3*3旋转正交矩阵自由度不是只有3?\n",
    "# identity rotation matrix eye(3)\n",
    "def identity_rot_mats(\n",
    "    batch_dims: Tuple[int], \n",
    "    dtype: Optional[torch.dtype] = None, \n",
    "    device: Optional[torch.device] = None, \n",
    "    requires_grad: bool = True,\n",
    ") -> torch.Tensor:\n",
    "    rots = torch.eye(\n",
    "        3, dtype=dtype, device=device, requires_grad=requires_grad\n",
    "    )\n",
    "    rots = rots.view(*((1,) * len(batch_dims)), 3, 3)\n",
    "    rots = rots.expand(*batch_dims, -1, -1)\n",
    "    rots = rots.contiguous()\n",
    "\n",
    "    return rots\n",
    "\n",
    "# identity translation vector [0,0,0]\n",
    "def identity_trans(\n",
    "    batch_dims: Tuple[int], \n",
    "    dtype: Optional[torch.dtype] = None,\n",
    "    device: Optional[torch.device] = None, \n",
    "    requires_grad: bool = True,\n",
    ") -> torch.Tensor:\n",
    "    trans = torch.zeros(\n",
    "        (*batch_dims, 3), \n",
    "        dtype=dtype, \n",
    "        device=device, \n",
    "        requires_grad=requires_grad\n",
    "    )\n",
    "    return trans\n",
    "\n",
    "# identity quaternion [1, 0, 0, 0]\n",
    "def identity_quats(\n",
    "    batch_dims: Tuple[int], \n",
    "    dtype: Optional[torch.dtype] = None,\n",
    "    device: Optional[torch.device] = None, \n",
    "    requires_grad: bool = True,\n",
    ") -> torch.Tensor:\n",
    "    quat = torch.zeros(\n",
    "        (*batch_dims, 4), \n",
    "        dtype=dtype, \n",
    "        device=device, \n",
    "        requires_grad=requires_grad\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # quat [* , 4] \n",
    "        quat[..., 0] = 1\n",
    "\n",
    "    return quat\n",
    "_quat_elements = [\"a\", \"b\", \"c\", \"d\"]\n",
    "_qtr_keys = [l1 + l2 for l1 in _quat_elements for l2 in _quat_elements]\n",
    "_qtr_ind_dict = {key: ind for ind, key in enumerate(_qtr_keys)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 1. IPA\n",
    "PS : \n",
    "1. H最开始肯定放在N_res后面,但是在attention score中一定是放在N_res前面，也就是H,N_res,N_res\n",
    "2. key,value是二维的情况下怎么画图\n",
    "\n",
    "\n",
    "总结：\n",
    "- 两套qkv,全部从single chain representation中得到\n",
    "  - qkv 为标准的多头注意力, 将c_s 投影为H * C_hidden\n",
    "  - q_pts, k_pts, v_pts 显示的构建了坐标的注意力机制,将c_s 投影为H*P_qk/P_v * 3,之后直接用Rigid transforamtion变换这些点点坐标\n",
    "- 三个attention score (affinities) 和一个bias\n",
    "  - pair-bias 由pair-representation直接将c_z投影到H的维度进行加和\n",
    "  - dot-product 由标准的多头注意力机制qkv计算得来\n",
    "  - squared distance affinities 由点注意力机制构建 $o_{pt} = -\\frac{\\gamma ^h W_c}{2}\\sum\\limits_{p}||q^{hp}_{i}-k^{hp}_{j} ||^2$\n",
    "    - 具体计算步骤就是输入一个[*, N_res, H, P_q, 3]的query q_pts和key k_pts\n",
    "    - pt_att = q_pts.unsqueeze(-4) - k_pts.unsqueeze(-5) query key氨基酸每个原子中的xyz坐标之差，利用brodcast来进行对称\n",
    "    - pt_att = pt_att** 2得到xyz距离平方\n",
    "    - pt_att = torch.sum(pt_att,dim=-1) 求和xyz坐标，得到每个residue的每个原子的坐标距离\n",
    "      - 源代码里是这样写的 sum(*torch.unbind(pt_att,dim=-1)),似乎没什么差别\n",
    "    - 加入weight\n",
    "    - 加入squared mask,常规操作:\n",
    "      - mask [*, N_res]\n",
    "      - -inf * (mask.unsqueeze(-1) * mask.unsqueeze(-2)).unsqueeze(-3) -> [*, 1, N_res, N_res]\n",
    "- 四个output value, 最后concat h,q\n",
    "  - pair-representation value\n",
    "    - [ *, H, N_res, N_res].transpose(-2,-3) @ [ *, N_res, N_res, c_z] -> [ *, N_res, H, c_z] -> [ *, N_res, H * c_z]\n",
    "  - dot-product value\n",
    "    - [ *, H, N_res, N_res] matmaul [ \\*, H, N_res, C_hidden] -> [ \\*, H, N_res ,C_hidden] -> [ *, N_res, H * C_hidden]\n",
    "  - o_pt (point attention value)\n",
    "    - input\n",
    "      - v_pts : [ *, N_res, H, P_v, 3] \n",
    "      - a     : [ *, H, N_res, N_res]\n",
    "    - output : o_pt : [ *, N_res, H, P_v, 3], split into 3 points : [ *, N_res, H * P_v] * 3\n",
    "  - o_pt_norm\n",
    "    - v_pts : $\\sqrt{v_{pts}^2}$\n",
    "- 1个输出\n",
    "  - 更新之后的s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From OpenFold\n",
    "class InvariantPointAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 22.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_s: int,\n",
    "        c_z: int,\n",
    "        c_hidden: int,\n",
    "        no_heads: int,\n",
    "        no_qk_points: int,\n",
    "        no_v_points: int,\n",
    "        inf: float = 1e5,\n",
    "        eps: float = 1e-8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            c_s:\n",
    "                Single representation channel dimension\n",
    "            c_z:\n",
    "                Pair representation channel dimension\n",
    "            c_hidden:\n",
    "                Hidden channel dimension\n",
    "            no_heads:\n",
    "                Number of attention heads\n",
    "            no_qk_points:\n",
    "                Number of query/key points to generate\n",
    "            no_v_points:\n",
    "                Number of value points to generate\n",
    "        \"\"\"\n",
    "        super(InvariantPointAttention, self).__init__()\n",
    "\n",
    "        self.c_s = c_s\n",
    "        self.c_z = c_z\n",
    "        self.c_hidden = c_hidden\n",
    "        self.no_heads = no_heads\n",
    "        self.no_qk_points = no_qk_points\n",
    "        self.no_v_points = no_v_points\n",
    "        self.inf = inf\n",
    "        self.eps = eps\n",
    "\n",
    "        # These linear layers differ from their specifications in the\n",
    "        # supplement. There, they lack bias and use Glorot initialization.\n",
    "        # Here as in the official source, they have bias and use the default\n",
    "        # Lecun initialization.\n",
    "        hc = self.c_hidden * self.no_heads\n",
    "        self.linear_q = Linear(self.c_s, hc)\n",
    "        self.linear_kv = Linear(self.c_s, 2 * hc) # 2*hc 表示一个是key,一个是value\n",
    "\n",
    "        hpq = self.no_heads * self.no_qk_points * 3 # 表示point attention 中 query 需要投影到的维度\n",
    "        self.linear_q_points = Linear(self.c_s, hpq)\n",
    "\n",
    "        hpkv = self.no_heads * (self.no_qk_points + self.no_v_points) * 3 # 表示point attention 中 key + value 需要投影到的维度\n",
    "        self.linear_kv_points = Linear(self.c_s, hpkv)\n",
    "\n",
    "        hpv = self.no_heads * self.no_v_points * 3\n",
    "\n",
    "        self.linear_b = Linear(self.c_z, self.no_heads)\n",
    "\n",
    "        self.head_weights = nn.Parameter(torch.zeros((no_heads))) # head weights 表示一个可学习的gamma h参数用来控制point attention affinity中的不同head\n",
    "        ipa_point_weights_init_(self.head_weights)\n",
    "\n",
    "        concat_out_dim = self.no_heads * (\n",
    "            self.c_z + self.c_hidden + self.no_v_points * 4\n",
    "        ) # 最终拼接时的dimension, c_z表示pair representation的output,  c_hidden 表示从single representaion计算的output, 4个no_v_points表示3个坐标(此处concat p)+1个norm；外侧乘H表示concat (H)\n",
    "        self.linear_out = Linear(concat_out_dim, self.c_s, init=\"final\")\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        s: torch.Tensor,\n",
    "        z: Optional[torch.Tensor],\n",
    "        r: Rigid,\n",
    "        mask: torch.Tensor,\n",
    "        inplace_safe: bool = False,\n",
    "        _offload_inference: bool = False,\n",
    "        _z_reference_list: Optional[Sequence[torch.Tensor]] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            s:\n",
    "                [*, N_res, C_s] single representation\n",
    "            z:\n",
    "                [*, N_res, N_res, C_z] pair representation\n",
    "            r:\n",
    "                [*, N_res] transformation object\n",
    "            mask:\n",
    "                [*, N_res] mask\n",
    "        Returns:\n",
    "            [*, N_res, C_s] single representation update\n",
    "        \"\"\"\n",
    "        if(_offload_inference and inplace_safe):\n",
    "            z = _z_reference_list\n",
    "        else:\n",
    "            z = [z]\n",
    "       \n",
    "        #######################################\n",
    "        # Generate scalar and point activations\n",
    "        #######################################\n",
    "        # [*, N_res, H * C_hidden]\n",
    "        q = self.linear_q(s)\n",
    "        kv = self.linear_kv(s)\n",
    "\n",
    "        # [*, N_res, H, C_hidden]\n",
    "        q = q.view(q.shape[:-1] + (self.no_heads, -1))\n",
    "\n",
    "        # [*, N_res, H, 2 * C_hidden]\n",
    "        kv = kv.view(kv.shape[:-1] + (self.no_heads, -1))\n",
    "\n",
    "        # [*, N_res, H, C_hidden]\n",
    "        k, v = torch.split(kv, self.c_hidden, dim=-1)\n",
    "\n",
    "        # [*, N_res, H * P_q * 3]\n",
    "        q_pts = self.linear_q_points(s)\n",
    "\n",
    "        # This is kind of clunky, but it's how the original does it\n",
    "        # 注意Rigid instance 做slicing的时候是对*做的(batch dimension)，而不用考虑最后的3*3\n",
    "        q_pts = torch.split(q_pts, q_pts.shape[-1] // 3, dim=-1)\n",
    "        # [*, N_res, H * P_q, 3]\n",
    "        q_pts = torch.stack(q_pts, dim=-1)\n",
    "        q_pts = r[..., None].apply(q_pts)\n",
    "\n",
    "        # [*, N_res, H, P_q, 3]\n",
    "        q_pts = q_pts.view(\n",
    "            q_pts.shape[:-2] + (self.no_heads, self.no_qk_points, 3)\n",
    "        )\n",
    "\n",
    "        # [*, N_res, H * (P_q + P_v) * 3]\n",
    "        kv_pts = self.linear_kv_points(s)\n",
    "\n",
    "        # [*, N_res, H * (P_q + P_v), 3]\n",
    "        kv_pts = torch.split(kv_pts, kv_pts.shape[-1] // 3, dim=-1)\n",
    "        kv_pts = torch.stack(kv_pts, dim=-1)\n",
    "        # r[...,None] -> \n",
    "        # Rigid : _rot       = [ *, N_res, 1, 3, 3]  \n",
    "        #         _trans     = [ *, N_res, 1, 3]\n",
    "        kv_pts = r[..., None].apply(kv_pts)\n",
    "\n",
    "\n",
    "        # [*, N_res, H, (P_q + P_v), 3]\n",
    "        kv_pts = kv_pts.view(kv_pts.shape[:-2] + (self.no_heads, -1, 3))\n",
    "\n",
    "        # [*, N_res, H, P_q/P_v, 3]\n",
    "        k_pts, v_pts = torch.split(\n",
    "            kv_pts, [self.no_qk_points, self.no_v_points], dim=-2\n",
    "        )\n",
    "\n",
    "        ##########################\n",
    "        # Compute attention scores\n",
    "        ##########################\n",
    "        # [*, N_res, N_res, H]\n",
    "        b = self.linear_b(z[0])\n",
    "        \n",
    "        if(_offload_inference):\n",
    "            assert(sys.getrefcount(z[0]) == 2)\n",
    "            z[0] = z[0].cpu()\n",
    "\n",
    "        # [*, H, N_res, N_res]\n",
    "        if(is_fp16_enabled()):\n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                a = torch.matmul(\n",
    "                    permute_final_dims(q.float(), (1, 0, 2)),  # [*, H, N_res, C_hidden]\n",
    "                    permute_final_dims(k.float(), (1, 2, 0)),  # [*, H, C_hidden, N_res]\n",
    "                )\n",
    "        else:\n",
    "            # q,k,v original [*, N_res, H, C_hidden]\n",
    "            a = torch.matmul(\n",
    "                permute_final_dims(q, (1, 0, 2)),  # [*, H, N_res, C_hidden]\n",
    "                permute_final_dims(k, (1, 2, 0)),  # [*, H, C_hidden, N_res]\n",
    "            ) # attention affinity [*, H, N_res, N_res] \n",
    "        \n",
    "        a *= math.sqrt(1.0 / (3 * self.c_hidden))\n",
    "        a += (math.sqrt(1.0 / 3) * permute_final_dims(b, (2, 0, 1)))\n",
    "        # bias from  [*, N_res, N_res, H] -> [*, H, N_res, N_res]\n",
    "\n",
    "        # [*, N_res, N_res, H, P_q, 3]\n",
    "        # Original q_pts,k_pts,v_pts after global transformation  -> [*, N_res, H, P_qk, 3]\n",
    "        # broadcast from [*, N_res, 1, H, P_q, 3] - [*, N_res, 1, H, P_q, 3]\n",
    "        pt_att = q_pts.unsqueeze(-4) - k_pts.unsqueeze(-5)\n",
    "        if(inplace_safe):\n",
    "            pt_att *= pt_att\n",
    "        else:\n",
    "            pt_att = pt_att ** 2\n",
    "\n",
    "        # [*, N_res, N_res, H, P_q]\n",
    "        pt_att = sum(torch.unbind(pt_att, dim=-1)) # 等价于 torch.sum(pt_att,dim=-1), 求两两点之间的膜长\n",
    "        head_weights = self.softplus(self.head_weights).view(\n",
    "            *((1,) * len(pt_att.shape[:-2]) + (-1, 1))\n",
    "        ) # [*, 1, 1, H, 1]\n",
    "        head_weights = head_weights * math.sqrt(\n",
    "            1.0 / (3 * (self.no_qk_points * 9.0 / 2))\n",
    "        )\n",
    "        if(inplace_safe):\n",
    "            pt_att *= head_weights\n",
    "        else:\n",
    "            pt_att = pt_att * head_weights\n",
    "\n",
    "        # [*, N_res, N_res, H]\n",
    "        pt_att = torch.sum(pt_att, dim=-1) * (-0.5)\n",
    "        # [*, N_res, N_res]\n",
    "        # Broadcast from [*, N_res, 1] * [*, 1, N_res]\n",
    "        square_mask = mask.unsqueeze(-1) * mask.unsqueeze(-2)\n",
    "        square_mask = self.inf * (square_mask - 1)\n",
    "\n",
    "        # [*, H, N_res, N_res]\n",
    "        pt_att = permute_final_dims(pt_att, (2, 0, 1))\n",
    "        \n",
    "        if(inplace_safe):\n",
    "            a += pt_att\n",
    "            del pt_att\n",
    "            a += square_mask.unsqueeze(-3)\n",
    "            # in-place softmax\n",
    "            attn_core_inplace_cuda.forward_(\n",
    "                a,\n",
    "                reduce(mul, a.shape[:-1]),\n",
    "                a.shape[-1],\n",
    "            )\n",
    "        else:\n",
    "            # a from dot-product affinities and bias , will be added point attention \n",
    "            a = a + pt_att \n",
    "            a = a + square_mask.unsqueeze(-3)\n",
    "            a = self.softmax(a)\n",
    "\n",
    "        ################\n",
    "        # Compute output\n",
    "        ################\n",
    "        # [*, N_res, H, C_hidden]\n",
    "        o = torch.matmul(\n",
    "            a, v.transpose(-2, -3).to(dtype=a.dtype)\n",
    "        ).transpose(-2, -3)\n",
    "\n",
    "        # [*, N_res, H * C_hidden]\n",
    "        o = flatten_final_dims(o, 2)\n",
    "\n",
    "        # [*, H, 3, N_res, P_v] \n",
    "        if(inplace_safe):\n",
    "            v_pts = permute_final_dims(v_pts, (1, 3, 0, 2))\n",
    "            o_pt = [\n",
    "                torch.matmul(a, v.to(a.dtype)) \n",
    "                for v in torch.unbind(v_pts, dim=-3)\n",
    "            ]\n",
    "            o_pt = torch.stack(o_pt, dim=-3)\n",
    "        else:\n",
    "            o_pt = torch.sum(\n",
    "                (\n",
    "                    a[..., None, :, :, None]\n",
    "                    * permute_final_dims(v_pts, (1, 3, 0, 2))[..., None, :, :]\n",
    "                ),\n",
    "                dim=-2,\n",
    "            )\n",
    "            # step by step\n",
    "            # a[...,None,:,:,None] from [*, H, N_res, N_res]                -> [*, H, 1, N_res, N_res,    1]\n",
    "            # v_pts from [*, N_res, H, P_v, 3] ->  [*, H, 3, N_res, P_v]    -> [*, H, 3, 1,     N_res,  P_v] \n",
    "            # 与 [*, H, N_res, N_res] @ [*, H, N_res, 3*P_v] 然后再把最后一个维度展开有啥区别?\n",
    "\n",
    "        # [*, N_res, H, P_v, 3]\n",
    "        o_pt = permute_final_dims(o_pt, (2, 0, 3, 1))\n",
    "        # _rot : [*, N_res, 1, 1, 3, 3], _trans : [*, N_res, 1, 1, 3]\n",
    "        o_pt = r[..., None, None].invert_apply(o_pt)\n",
    "\n",
    "        # [*, N_res, H * P_v]\n",
    "        o_pt_norm = flatten_final_dims(\n",
    "            torch.sqrt(torch.sum(o_pt ** 2, dim=-1) + self.eps), 2\n",
    "        )\n",
    "\n",
    "        # [*, N_res, H * P_v, 3]\n",
    "        o_pt = o_pt.reshape(*o_pt.shape[:-3], -1, 3)\n",
    "\n",
    "        if(_offload_inference):\n",
    "            z[0] = z[0].to(o_pt.device)\n",
    "\n",
    "        # [*, N_res, H, C_z]\n",
    "        # [*, N_res, H, N_res] @ [*, N_res, N_res, c_z] -> [*, N_res, H, c_z]\n",
    "        o_pair = torch.matmul(a.transpose(-2, -3), z[0].to(dtype=a.dtype))\n",
    "\n",
    "        # [*, N_res, H * C_z]\n",
    "        o_pair = flatten_final_dims(o_pair, 2)\n",
    "\n",
    "        # [*, N_res, C_s]\n",
    "        s = self.linear_out(\n",
    "            torch.cat(\n",
    "                (o, *torch.unbind(o_pt, dim=-1), o_pt_norm, o_pair), dim=-1\n",
    "            ).to(dtype=z[0].dtype)\n",
    "            # concat list : H * (4*P_v + C_z + c_hidden)\n",
    "            # o : [*, N_res, H*c_hidden]\n",
    "            # * torch.unbind(o_pt, dim=-1),解压每一个坐标的维度 \n",
    "            # - o_pt_p1 [*, N_res, H*P_v]\n",
    "            # - o_pt_p2 [*, N_res, H*P_v]\n",
    "            # - o_pt_p3 [*, N_res, H*P_v]\n",
    "            # o_pt_norm : [*, N_res, H*P_v]\n",
    "            # o_pair    : [*, N_res, H*C_z]\n",
    "        )\n",
    "        \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (v3.8.8:024d8058b0, Feb 19 2021, 08:48:17) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
