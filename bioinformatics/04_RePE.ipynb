{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05.24 RoPE (Rotary Positional Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    # x (query or key vector) : [B, L, dim]\n",
    "    # cos (cosine table)      : [1, _seq_len_cached, dim]\n",
    "    # sin (sine table)        : [1, _seq_len_cached, dim]\n",
    "    cos = cos[:, : x.shape[-2], :]\n",
    "    sin = sin[:, : x.shape[-2], :]\n",
    "\n",
    "    return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "\n",
    "class RotaryEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The rotary position embeddings from RoFormer_ (Su et. al).\n",
    "    A crucial insight from the method is that the query and keys are\n",
    "    transformed by rotation matrices which depend on the relative positions.\n",
    "    Other implementations are available in the Rotary Transformer repo_ and in\n",
    "    GPT-NeoX_, GPT-NeoX was an inspiration\n",
    "    .. _RoFormer: https://arxiv.org/abs/2104.09864\n",
    "    .. _repo: https://github.com/ZhuiyiTechnology/roformer\n",
    "    .. _GPT-NeoX: https://github.com/EleutherAI/gpt-neox\n",
    "    .. warning: Please note that this embedding is not registered on purpose, as it is transformative\n",
    "        (it does not create the embedding dimension) and will likely be picked up (imported) on a ad-hoc basis\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int, *_, **__):\n",
    "        super().__init__()\n",
    "        # Generate and save the inverse frequency buffer (non trainable)\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim)) # theta1, theta2 .... theta dim/2\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "        self._seq_len_cached = None\n",
    "        self._cos_cached = None\n",
    "        self._sin_cached = None\n",
    "\n",
    "    def _update_cos_sin_tables(self, x, seq_dimension=1):\n",
    "        seq_len = x.shape[seq_dimension]\n",
    "\n",
    "        # Reset the tables if the sequence length has changed,\n",
    "        # or if we're on a new device (possibly due to tracing for instance)\n",
    "        if seq_len != self._seq_len_cached or self._cos_cached.device != x.device:\n",
    "            self._seq_len_cached = seq_len\n",
    "            t = torch.arange(x.shape[seq_dimension], device=x.device).type_as(self.inv_freq) # seq_len : 1, 2, ... , L (position)\n",
    "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq) # [seq_len, dim/2] : position_m theta_1 , position_m theta_2, ... , position_m theta_dim/2\n",
    "            emb = torch.cat((freqs, freqs), dim=-1).to(x.device) # cat [seq_len, dim/2] -> [seq_len, dim]\n",
    "\n",
    "            self._cos_cached = emb.cos()[None, :, :]\n",
    "            self._sin_cached = emb.sin()[None, :, :]\n",
    "\n",
    "        return self._cos_cached, self._sin_cached\n",
    "\n",
    "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        self._cos_cached, self._sin_cached = self._update_cos_sin_tables(k, seq_dimension=-2)\n",
    "\n",
    "        return (\n",
    "            apply_rotary_pos_emb(q, self._cos_cached, self._sin_cached),\n",
    "            apply_rotary_pos_emb(k, self._cos_cached, self._sin_cached),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "length = 5\n",
    "dim = 8\n",
    "query = torch.randn((batch,length,dim))\n",
    "key = torch.randn((batch,length,dim))\n",
    "rope = RotaryEmbedding(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.1000, 0.0100, 0.0010])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/10000**(6/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
